<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="author" content="[Alok Regmi]">
<meta name="description" content="TODO Gain Curve Writing formulas formula_obj &lt;- var1 ~ var2 formula_obj &lt;- var1 ~ var2 &#43; var3 formula_obj &lt;- as.formula(&#34;var1 ~ var2&#34;) Getting information about the model print(model_var) summary(model_var) broom::glance(model_var) sigr:wrapFTest(model_var) print shows the basic formula used and the coefficients for the model. summary shows the formula, coefficients, residuals as well as probabilistic statistics such as R^2 value and so on. glance shows the whole data from summary in the form of nice dataframe with columns such as df.residual, sigma and so on. wrapFTest shows the most relevant details of the model. Predicting using the model predict(model, newdata = new_data_vals) Collinearity The variables assumed to be independent might not be independent after all. Unusually high collinearity may make model unstable though. Gain curve The gain curve is important in sorting the outcome rather than making all predictions correct. Checks if model&rsquo;s predictions sort in the same order as the true outcome.
" />
<meta name="keywords" content="Blog" />
<meta name="robots" content="noodp" />
<meta name="theme-color" content="" />
<link rel="canonical" href="https://dragarok.github.io/braindump/2020/10/r-programming-105-supervised-learning-2-regression/" />


    <title>
        
            R Programming 105- Supervised Learning 2 Regression ::  
        
    </title>



<link href="https://cdnjs.cloudflare.com/ajax/libs/flag-icon-css/3.2.1/css/flag-icon.min.css" rel="stylesheet"
    type="text/css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
    
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
    
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>





<link rel="stylesheet" href="../../../../main.min.daa43c14e17ef1950fa593909b64d3a2d9855d65b354823b6d82fca285818e75.css">




    <link rel="apple-touch-icon" sizes="180x180" href="../../../../apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="../../../../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../../../../favicon-16x16.png">
    <link rel="manifest" href="../../../../site.webmanifest">
    <link rel="mask-icon" href="../../../../safari-pinned-tab.svg" color="#252627">
    <link rel="shortcut icon" href="../../../../favicon.ico">
    <meta name="msapplication-TileColor" content="#252627">
    <meta name="theme-color" content="#252627">


  <meta itemprop="name" content="R Programming 105- Supervised Learning 2 Regression">
  <meta itemprop="description" content="TODO Gain Curve Writing formulas formula_obj &lt;- var1 ~ var2 formula_obj &lt;- var1 ~ var2 &#43; var3 formula_obj &lt;- as.formula(&#34;var1 ~ var2&#34;) Getting information about the model print(model_var) summary(model_var) broom::glance(model_var) sigr:wrapFTest(model_var) print shows the basic formula used and the coefficients for the model. summary shows the formula, coefficients, residuals as well as probabilistic statistics such as R^2 value and so on. glance shows the whole data from summary in the form of nice dataframe with columns such as df.residual, sigma and so on. wrapFTest shows the most relevant details of the model. Predicting using the model predict(model, newdata = new_data_vals) Collinearity The variables assumed to be independent might not be independent after all. Unusually high collinearity may make model unstable though. Gain curve The gain curve is important in sorting the outcome rather than making all predictions correct. Checks if model’s predictions sort in the same order as the true outcome.">
  <meta itemprop="datePublished" content="2020-10-08T00:00:00+05:45">
  <meta itemprop="dateModified" content="2020-10-09T10:40:57+05:45">
  <meta itemprop="wordCount" content="957">
  <meta itemprop="image" content="https://dragarok.github.io/">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="https://dragarok.github.io/">
  <meta name="twitter:title" content="R Programming 105- Supervised Learning 2 Regression">
  <meta name="twitter:description" content="TODO Gain Curve Writing formulas formula_obj &lt;- var1 ~ var2 formula_obj &lt;- var1 ~ var2 &#43; var3 formula_obj &lt;- as.formula(&#34;var1 ~ var2&#34;) Getting information about the model print(model_var) summary(model_var) broom::glance(model_var) sigr:wrapFTest(model_var) print shows the basic formula used and the coefficients for the model. summary shows the formula, coefficients, residuals as well as probabilistic statistics such as R^2 value and so on. glance shows the whole data from summary in the form of nice dataframe with columns such as df.residual, sigma and so on. wrapFTest shows the most relevant details of the model. Predicting using the model predict(model, newdata = new_data_vals) Collinearity The variables assumed to be independent might not be independent after all. Unusually high collinearity may make model unstable though. Gain curve The gain curve is important in sorting the outcome rather than making all predictions correct. Checks if model’s predictions sort in the same order as the true outcome.">





    <meta property="article:published_time" content="2020-10-08 00:00:00 &#43;0545 &#43;0545" />








    </head>

    <body class="">
        <div class="container">
            <header class="header">
    <span class="header__inner">
        <a href="../../../../" style="text-decoration: none;">
    <div class="logo">
        
            <span class="logo__mark">~</span>
            <span class="logo__text">K4iv41y4</span>
            <span class="logo__mark">&nbsp;~</span>
            <span class="logo__cursor" style=
                  "
                   
                   ">
            </span>
        
    </div>
</a>


        <span class="header__right">
            
                <nav class="menu">
    <ul class="menu__inner"><li><a href="https://dragarok.github.io/about/">About</a></li><li><a href="https://dragarok.github.io/ai/">AI</a></li><li><a href="https://dragarok.github.io/posts/">Blog</a></li><li><a href="https://dragarok.github.io/books/">Books</a></li><li><a href="https://dragarok.github.io/braindump/">Braindump</a></li>
    </ul>
</nav>

                <span class="menu-trigger">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                        <path d="M0 0h24v24H0z" fill="none"/>
                        <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
                    </svg>
                </span>
            

            <span class="theme-toggle unselectable"><svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg">
  <path d="M22 41C32.4934 41 41 32.4934 41 22C41 11.5066 32.4934 3 22
  3C11.5066 3 3 11.5066 3 22C3 32.4934 11.5066 41 22 41ZM7 22C7
  13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22Z"/>
</svg>
</span>
        </span>
    </span>
</header>


            <div class="content">
                
    <main class="post">

        <div class="post-info">
            <p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-clock"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg>5 minutes

            

            </p>
        </div>

        <article>
            <h1 class="post-title">
                <a href="https://dragarok.github.io/braindump/2020/10/r-programming-105-supervised-learning-2-regression/">R Programming 105- Supervised Learning 2 Regression</a>
            </h1>

            

            <div class="post-content">
                <h2 id="gain-curve"><span class="org-todo todo TODO">TODO</span> Gain Curve</h2>
<h3 id="writing-formulas">Writing formulas</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-R" data-lang="R"><span style="display:flex;"><span>formula_obj <span style="color:#f92672">&lt;-</span> var1 <span style="color:#f92672">~</span> var2
</span></span><span style="display:flex;"><span>formula_obj <span style="color:#f92672">&lt;-</span> var1 <span style="color:#f92672">~</span> var2 <span style="color:#f92672">+</span> var3
</span></span><span style="display:flex;"><span>formula_obj <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">as.formula</span>(<span style="color:#e6db74">&#34;var1 ~ var2&#34;</span>)
</span></span></code></pre></div><h3 id="getting-information-about-the-model">Getting information about the model</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-R" data-lang="R"><span style="display:flex;"><span><span style="color:#a6e22e">print</span>(model_var)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">summary</span>(model_var)
</span></span><span style="display:flex;"><span>broom<span style="color:#f92672">::</span><span style="color:#a6e22e">glance</span>(model_var)
</span></span><span style="display:flex;"><span>sigr<span style="color:#f92672">:</span><span style="color:#a6e22e">wrapFTest</span>(model_var)
</span></span></code></pre></div><ul>
<li><em>print</em> shows the basic formula used and the coefficients for the model.</li>
<li><em>summary</em> shows the formula, coefficients, residuals as well as probabilistic statistics such as R^2 value and so on.</li>
<li><em>glance</em> shows the whole data from summary in the form of nice dataframe with columns such as <strong>df.residual</strong>, <strong>sigma</strong> and so on.</li>
<li><em>wrapFTest</em> shows the most relevant details of the model.</li>
</ul>
<h3 id="predicting-using-the-model">Predicting using the model</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-R" data-lang="R"><span style="display:flex;"><span><span style="color:#a6e22e">predict</span>(model, newdata <span style="color:#f92672">=</span> new_data_vals)
</span></span></code></pre></div><h3 id="collinearity">Collinearity</h3>
<ul>
<li>The variables assumed to be independent might not be independent after all.</li>
<li>Unusually high collinearity may make model unstable though.</li>
</ul>
<h3 id="gain-curve">Gain curve</h3>
<p>The gain curve is important in sorting the outcome rather than making all predictions correct. Checks if model&rsquo;s predictions sort in the same order as the true outcome.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-R" data-lang="R"><span style="display:flex;"><span><span style="color:#a6e22e">library</span>(WVPlots)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">GainCurvePlot</span>(df_var, predictions, actual_value, title_for_plot)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">GainCurvePlot</span>(frame, xvar, truthvar, title)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">GainCurvePlot</span>(df_name, <span style="color:#e6db74">&#34;pred_col_name&#34;</span>, <span style="color:#e6db74">&#34;actual_col_name&#34;</span> , <span style="color:#e6db74">&#34;Title of plot&#34;</span>)
</span></span></code></pre></div><p>Here, the <em>column names</em> need to be passed as strings or else these objects cannot be found when creating the plot.</p>
<h3 id="rmse">RMSE</h3>
<p>RMSE much smaller than the outcome&rsquo;s standard deviation suggests that a model predicts well.</p>
<h3 id="r-2">R^2</h3>
<p>Variance explained by the model
\[R^{2}=1-\frac{R S S}{S S_{T o t}}\]
where RSS = Residual sum of squares i.e. Variance of model and
\[SS_{TOT}\] = Total sum of squares i.e. Variance of data
Having large R^2 means that the model fits the data well.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-R" data-lang="R"><span style="display:flex;"><span><span style="color:#a6e22e">summary</span>(model_var)<span style="color:#f92672">$</span>r.squared
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">glance</span>(model_var)<span style="color:#f92672">$</span>r.squared
</span></span></code></pre></div><p>The summary function for linear model using <em>lm()</em> returns the R^2 error already there.</p>
<h3 id="cross-validation">Cross Validation</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-R" data-lang="R"><span style="display:flex;"><span><span style="color:#a6e22e">library</span>(vtreat)
</span></span><span style="display:flex;"><span>splitWay <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">kWayCrossValidation</span>(n_rows, n_splits, <span style="color:#66d9ef">NULL</span>, <span style="color:#66d9ef">NULL</span>)
</span></span><span style="display:flex;"><span>splitWay[[index]]
</span></span></code></pre></div><p>The last two parameters are <em>df</em> and <em>y</em> ; these parameters are just for compatibility purposes.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-R" data-lang="R"><span style="display:flex;"><span><span style="color:#66d9ef">for</span> ( i <span style="color:#66d9ef">in</span> <span style="color:#ae81ff">1</span><span style="color:#f92672">:</span>num_folds ) {
</span></span><span style="display:flex;"><span>  split_ind <span style="color:#f92672">&lt;-</span> splitObject[[i]]
</span></span><span style="display:flex;"><span>  model <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">lm</span>(formula, data <span style="color:#f92672">=</span> df[split_ind<span style="color:#f92672">$</span>train,])
</span></span><span style="display:flex;"><span>  df<span style="color:#f92672">$</span>predictions[split_ind<span style="color:#f92672">$</span>app] <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">predict</span>(model, newdata <span style="color:#f92672">=</span> df[split_ind<span style="color:#f92672">$</span>app, ])
</span></span><span style="display:flex;"><span>    }
</span></span></code></pre></div><p>The test indexes are named as <em>app</em> and can be used as used in the code snippet above.</p>
<h3 id="random-train-test-split">Random train test split</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-R" data-lang="R"><span style="display:flex;"><span>train_size <span style="color:#f92672">&lt;-</span> <span style="color:#ae81ff">0.8</span> <span style="color:#f92672">*</span> total_size
</span></span><span style="display:flex;"><span>tot_ind <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">runif</span>(total_size)
</span></span><span style="display:flex;"><span>df_train <span style="color:#f92672">&lt;-</span> df[tot_ind <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">0.75</span>, ]
</span></span><span style="display:flex;"><span>df_test <span style="color:#f92672">&lt;-</span> df[tot_ind <span style="color:#f92672">&gt;=</span> <span style="color:#ae81ff">0.75</span>, ]
</span></span></code></pre></div><h3 id="one-hot-encoding">One Hot Encoding</h3>
<p>Every categorical variable is encoded under the hood as numerical values from 0 to N-1 by R itself.
But with too many levels, this can be a problem.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-R" data-lang="R"><span style="display:flex;"><span>mmat <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">model.matrix</span>(formula, data)
</span></span></code></pre></div><p>Doing this you know how exactly is R changing the dataframe for you to be fitted to any model later.</p>
<!--list-separator-->
<ul>
<li>
<p>Creating treatment plans</p>
<p>The treatment plans help to work on specific columns from the data in a certain way such as creating levels on categorical data and removing NAs from numerical data.</p>
<p>:ID:       e664edf5-fc3e-488e-85e4-cd802f1ad389</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-R" data-lang="R"><span style="display:flex;"><span><span style="color:#a6e22e">designTreatmentsZ</span>(dframe, varslist, verbose <span style="color:#f92672">=</span> <span style="color:#66d9ef">FALSE</span>)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">prepare</span>(treatmentPlan, dframe, varRestriction <span style="color:#f92672">=</span> new_vars_list)
</span></span></code></pre></div><p>You need to use the treatment plan on test data as well before predicting the output.</p>
</li>
</ul>
<h3 id="variables-interactions">Variables Interactions</h3>
<p>When representing variables as formulas, there are chances that the variables will be related as well which need to be incorporated into the formula itself.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-R" data-lang="R"><span style="display:flex;"><span>dep_var <span style="color:#f92672">&lt;-</span> var_1 <span style="color:#f92672">+</span> var_2 <span style="color:#f92672">+</span> var_1<span style="color:#f92672">:</span>var_2
</span></span></code></pre></div><p>The two variables separated by column are dependent on each other. So, we need to map that relation too.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-R" data-lang="R"><span style="display:flex;"><span>dep_var <span style="color:#f92672">&lt;-</span> var_1 <span style="color:#f92672">*</span> var_2
</span></span></code></pre></div><p>The <em>asterisk</em> means the same as the formula we wrote above.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-R" data-lang="R"><span style="display:flex;"><span>dep_var <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">I</span>(var_1, var_2)
</span></span></code></pre></div><p>This expresses the product of two variables in the formula.</p>
<h3 id="transforming-variables">Transforming Variables</h3>
<p>The variables can be changed based on some information that we have priorly.</p>
<h3 id="logistic-regression">Logistic Regression</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-R" data-lang="R"><span style="display:flex;"><span><span style="color:#a6e22e">glm</span>(formula, data, family <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;binomial&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">predict</span>(model, newdata, type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;response&#34;</span>)
</span></span></code></pre></div><ul>
<li>Deviance and Null Deviance instead of SSE and SST.</li>
</ul>
<!--listend-->
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-R" data-lang="R"><span style="display:flex;"><span><span style="color:#a6e22e">wrapChiSqTest</span>(<span style="color:#e6db74">&#34;pred_col&#34;</span>, <span style="color:#e6db74">&#34;actual_col&#34;</span>, <span style="color:#e6db74">&#34;tgt_event&#34;</span>)
</span></span></code></pre></div><p>We can also use <em>GainCurvePlot</em> to see the effectiveness of the model.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-R" data-lang="R"><span style="display:flex;"><span>out_df <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">glance</span>(glm_model)
</span></span><span style="display:flex;"><span>pseudo_r2 <span style="color:#f92672">&lt;-</span> <span style="color:#ae81ff">1</span> <span style="color:#f92672">-</span> ( out_df<span style="color:#f92672">$</span>deviance <span style="color:#f92672">/</span> out_df<span style="color:#f92672">$</span>null_deviance )
</span></span></code></pre></div><h3 id="poission-and-quasipoisson-regression">Poission and QuasiPoisson Regression</h3>
<ul>
<li>Mean is equal to or in simlar order as the Variance means a Poisson Distribution.</li>
<li><em>family = &ldquo;Poisson&rdquo;</em> or <em>family = &ldquo;quasipoisson&rdquo;</em> is used.</li>
<li>Used to predict counts.</li>
<li>Inputs additive and linear in log(count)</li>
<li>Mean is different from Variance in a Quasi Poisson distribution.</li>
<li>Similar to Logistic Regression, pseudo R^2 can be found with a similar process.</li>
</ul>
<h3 id="generalized-additive-models">Generalized Additive Models</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-R" data-lang="R"><span style="display:flex;"><span><span style="color:#a6e22e">library</span>(mgcv)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">gam</span>(formula, family, data)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">s</span>(col_name) <span style="color:#75715e"># fit a smooth function</span>
</span></span><span style="display:flex;"><span>fmla <span style="color:#f92672">&lt;-</span> dep_col <span style="color:#f92672">~</span> <span style="color:#a6e22e">s</span>(ind_col_1)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">plot</span>(gam_model)
</span></span></code></pre></div><ul>
<li>family = &ldquo;gaussian&rdquo; or &ldquo;poisson&rdquo; or &ldquo;binomial&rdquo;</li>
<li>Best for larger data sets since they are more complex.</li>
<li>Can pass smooth function to continuous variables only.</li>
<li>Predict function for this model gives output as matrix; so need to use <em>as.numeric()</em> to get the output.</li>
</ul>
<h3 id="tree-based-methods">Tree Based Methods</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-R" data-lang="R"><span style="display:flex;"><span><span style="color:#a6e22e">library</span>(ranger)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">ranger</span>(fmla,
</span></span><span style="display:flex;"><span>       data,
</span></span><span style="display:flex;"><span>       num.trees <span style="color:#f92672">=</span> number,
</span></span><span style="display:flex;"><span>       respect.unordered.factors <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;order&#34;</span>)
</span></span></code></pre></div><ul>
<li><em>mtry</em> : number of variables to try at each node.</li>
</ul>
<!--list-separator-->
<ul>
<li>
<p>Gradient Boosting</p>
<ol>
<li>Fit a shallow tree T1 to the data. M1 = T1</li>
<li>Fit tree T2 to the residuals and find λ such that  M2 = M1 + λ * T2</li>
<li>For regularized learning, add a regularization parameter η ranging from 0 to 1 where smaller η means slow learning and higher means faster learning.</li>
</ol>
 <!--listend-->
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-R" data-lang="R"><span style="display:flex;"><span><span style="color:#a6e22e">library</span>(xgboost)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">xgb.cv</span>() <span style="color:#75715e"># evaluation_log has the rmse for each round and used to find the optimum model</span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">xgb.cv</span>(data <span style="color:#f92672">=</span> <span style="color:#a6e22e">as.matrix</span>(treatedData),
</span></span><span style="display:flex;"><span>       label <span style="color:#f92672">=</span> df<span style="color:#f92672">$</span>res_col,
</span></span><span style="display:flex;"><span>       objective <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;reg:linear&#34;</span>,
</span></span><span style="display:flex;"><span>       nrounds <span style="color:#f92672">=</span> <span style="color:#ae81ff">200</span>,
</span></span><span style="display:flex;"><span>       nfold <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>,
</span></span><span style="display:flex;"><span>       eta <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.2</span>,
</span></span><span style="display:flex;"><span>       depth <span style="color:#f92672">=</span> <span style="color:#ae81ff">8</span>)
</span></span></code></pre></div> <!--list-separator-->
<ul>
<li>
<p>Arguments</p>
<ol>
<li>Data as matrix</li>
<li>Nrounds with maximum number of trees to fit.</li>
<li>Eta as learning rate</li>
<li>Depth as maximum depth of single tree</li>
<li>Nfolds to specify how many cross validation folds to be made.</li>
<li>Objective with what kind of model to be fitted.</li>
</ol>
</li>
</ul>
 <!--list-separator-->
<ul>
<li>
<p>Finding best number of trees</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-R" data-lang="R"><span style="display:flex;"><span>elog <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">as.data.frame</span>(cv<span style="color:#f92672">$</span>evaluation_log)
</span></span><span style="display:flex;"><span>nrounds <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">which.min</span>(elog<span style="color:#f92672">$</span>test_rmse_mean)
</span></span></code></pre></div><p>First you get the evaluation log and then find the position with minimum rmse. Then use <em>xgboost()</em> to create the final model for prediction.
You need to note that the predict function also takes a matrix when using a xgboost model for prediction.</p>
</li>
</ul>
</li>
</ul>
<h2 id="backlinks">Backlinks</h2>
<ul>
<li><a href="../../../../braindump/2020/09/data-scientist-with-r/">Data Scientist with R</a></li>
</ul>

            </div>
        </article>

        <hr />

        <div class="post-info">

            <p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline><line x1="16" y1="13" x2="8" y2="13"></line><line x1="16" y1="17" x2="8" y2="17"></line><polyline points="10 9 9 9 8 9"></polyline></svg>957 Words</p>

            <p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg>2020-10-08 00:00 &#43;0545</p>
        </div>

        
            <div class="pagination">
                <div class="pagination__title">
                    <span class="pagination__title-h">Read other post</span>
                    <hr />
                </div>

                <div class="pagination__buttons">
                    
                        <span class="button previous">
                            <a href="https://dragarok.github.io/braindump/2020/10/r-programming-105-supervised-learning-1/">
                                <span class="button__icon">←</span>
                                <span class="button__text">R Programming 105- Supervised Learning 1</span>
                            </a>
                        </span>
                    

                    
                        <span class="button next">
                            <a href="https://dragarok.github.io/braindump/2020/10/r-programming-104-correlation-and-regression/">
                                <span class="button__text">R Programming 104- Correlation and Regression</span>
                                <span class="button__icon">→</span>
                            </a>
                        </span>
                    
                </div>
            </div>
        

        
    </main>

            </div>

        </div>

        




<script type="text/javascript" src="../../../../bundle.min.74fe699bb673e8362137b575513abfcf73303855d923eea09c0e507deab0ca7f8321880b672790b9e63cc109a18189deebfd13899a8ff536e858791973ffd487.js" integrity="sha512-dP5pm7Zz6DYhN7V1UTq/z3MwOFXZI&#43;6gnA5Qfeqwyn&#43;DIYgLZyeQueY8wQmhgYne6/0TiZqP9TboWHkZc//Uhw=="></script>



    </body>
</html>

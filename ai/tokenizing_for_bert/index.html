<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="author" content="[Alok Regmi]">
<meta name="description" content="&amp;quot;&amp;quot;&amp;quot; Adapted from Oliver Atanaszov&amp;rsquo;s notebook on transformer fine-tuning https://github.com/ben0it8/containerized-transformer-finetuning/blob/develop/research/finetune-transformer-on-imdb5k.ipynb &amp;quot;&amp;quot;&amp;quot;
from concurrent.futures import ProcessPoolExecutor import multiprocessing import os import numpy as np import pandas as pd import torch from torch.utils.data import TensorDataset, random_split, DataLoader from tqdm import tqdm n_cpu = multiprocessing.cpu_count() MAX_LENGTH = 256 class TextProcessor: def __init__(self, tokenizer, label2id: dict, max_length: int=512): self.tokenizer = tokenizer self.label2id = label2id self.max_length = max_length self.clf_token = self.tokenizer.vocab[&amp;#39;[CLS]&amp;#39;] self.pad_token = self.tokenizer.vocab[&amp;#39;[PAD]&amp;#39;] def encode(self, input): return list(self." />
<meta name="keywords" content="Blog, tokenization, bert" />
<meta name="robots" content="noodp" />
<meta name="theme-color" content="" />
<link rel="canonical" href="https://dragarok.github.io/ai/tokenizing_for_bert/" />


    <title>
        
            Bert Tokenization :: Alok&#39;s Blog 
        
    </title>



<link href="https://cdnjs.cloudflare.com/ajax/libs/flag-icon-css/3.2.1/css/flag-icon.min.css" rel="stylesheet"
    type="text/css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
    
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
    
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>





<link rel="stylesheet" href="../../main.min.84ed5579024525d4b50458514d1a43e40dd5272df45c7cd6da85b225af457154.css">




    <link rel="apple-touch-icon" sizes="180x180" href="../../apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../../favicon-16x16.png">
    <link rel="manifest" href="../../site.webmanifest">
    <link rel="mask-icon" href="../../safari-pinned-tab.svg" color="#252627">
    <link rel="shortcut icon" href="../../favicon.ico">
    <meta name="msapplication-TileColor" content="#252627">
    <meta name="theme-color" content="#252627">

<meta itemprop="name" content="Bert Tokenization">
<meta itemprop="description" content="&quot;&quot;&quot; Adapted from Oliver Atanaszov&rsquo;s notebook on transformer fine-tuning https://github.com/ben0it8/containerized-transformer-finetuning/blob/develop/research/finetune-transformer-on-imdb5k.ipynb &quot;&quot;&quot;
from concurrent.futures import ProcessPoolExecutor import multiprocessing import os import numpy as np import pandas as pd import torch from torch.utils.data import TensorDataset, random_split, DataLoader from tqdm import tqdm n_cpu = multiprocessing.cpu_count() MAX_LENGTH = 256 class TextProcessor: def __init__(self, tokenizer, label2id: dict, max_length: int=512): self.tokenizer = tokenizer self.label2id = label2id self.max_length = max_length self.clf_token = self.tokenizer.vocab[&#39;[CLS]&#39;] self.pad_token = self.tokenizer.vocab[&#39;[PAD]&#39;] def encode(self, input): return list(self.">
<meta itemprop="datePublished" content="2020-01-24T00:00:00+05:45" />
<meta itemprop="dateModified" content="2020-06-16T07:35:03+05:45" />
<meta itemprop="wordCount" content="255">
<meta itemprop="image" content="https://dragarok.github.io/"/>



<meta itemprop="keywords" content="tokenization,bert," />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://dragarok.github.io/"/>

<meta name="twitter:title" content="Bert Tokenization"/>
<meta name="twitter:description" content="&quot;&quot;&quot; Adapted from Oliver Atanaszov&rsquo;s notebook on transformer fine-tuning https://github.com/ben0it8/containerized-transformer-finetuning/blob/develop/research/finetune-transformer-on-imdb5k.ipynb &quot;&quot;&quot;
from concurrent.futures import ProcessPoolExecutor import multiprocessing import os import numpy as np import pandas as pd import torch from torch.utils.data import TensorDataset, random_split, DataLoader from tqdm import tqdm n_cpu = multiprocessing.cpu_count() MAX_LENGTH = 256 class TextProcessor: def __init__(self, tokenizer, label2id: dict, max_length: int=512): self.tokenizer = tokenizer self.label2id = label2id self.max_length = max_length self.clf_token = self.tokenizer.vocab[&#39;[CLS]&#39;] self.pad_token = self.tokenizer.vocab[&#39;[PAD]&#39;] def encode(self, input): return list(self."/>





    <meta property="article:published_time" content="2020-01-24 00:00:00 &#43;0545 &#43;0545" />








    </head>

    <body class="">
        <div class="container">
            <header class="header">
    <span class="header__inner">
        <a href="../../" style="text-decoration: none;">
    <div class="logo">
        
            <span class="logo__mark">~</span>
            <span class="logo__text">K4iv41y4</span>
            <span class="logo__mark">&nbsp;~</span>
            <span class="logo__cursor" style=
                  "
                   
                   ">
            </span>
        
    </div>
</a>


        <span class="header__right">
            
                <nav class="menu">
    <ul class="menu__inner"><li><a href="https://dragarok.github.io/about/">About</a></li><li><a href="https://dragarok.github.io/ai/">AI</a></li><li><a href="https://dragarok.github.io/posts/">Blog</a></li><li><a href="https://dragarok.github.io/books/">Books</a></li><li><a href="https://dragarok.github.io/braindump/">Braindump</a></li>
    </ul>
</nav>

                <span class="menu-trigger">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                        <path d="M0 0h24v24H0z" fill="none"/>
                        <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
                    </svg>
                </span>
            

            <span class="theme-toggle unselectable"><svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg">
  <path d="M22 41C32.4934 41 41 32.4934 41 22C41 11.5066 32.4934 3 22
  3C11.5066 3 3 11.5066 3 22C3 32.4934 11.5066 41 22 41ZM7 22C7
  13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22Z"/>
</svg>
</span>
        </span>
    </span>
</header>


            <div class="content">
                
    <main class="post">

        <div class="post-info">
            
            </p>
        </div>

        <article>
            <h2 class="post-title"><a href="https://dragarok.github.io/ai/tokenizing_for_bert/">Bert Tokenization</a></h2>

            

            <div class="post-content">
                <p>&quot;&quot;&quot;
Adapted from Oliver Atanaszov&rsquo;s notebook on transformer fine-tuning
<a href="https://github.com/ben0it8/containerized-transformer-finetuning/blob/develop/research/finetune-transformer-on-imdb5k.ipynb">https://github.com/ben0it8/containerized-transformer-finetuning/blob/develop/research/finetune-transformer-on-imdb5k.ipynb</a>
&quot;&quot;&quot;</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> concurrent.futures <span style="color:#f92672">import</span> ProcessPoolExecutor
<span style="color:#f92672">import</span> multiprocessing
<span style="color:#f92672">import</span> os
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> pandas <span style="color:#f92672">as</span> pd
<span style="color:#f92672">import</span> torch
<span style="color:#f92672">from</span> torch.utils.data <span style="color:#f92672">import</span> TensorDataset, random_split, DataLoader
<span style="color:#f92672">from</span> tqdm <span style="color:#f92672">import</span> tqdm

n_cpu <span style="color:#f92672">=</span> multiprocessing<span style="color:#f92672">.</span>cpu_count()
MAX_LENGTH <span style="color:#f92672">=</span> <span style="color:#ae81ff">256</span>

<span style="color:#66d9ef">class</span> <span style="color:#a6e22e">TextProcessor</span>:
    <span style="color:#66d9ef">def</span> __init__(self, tokenizer, label2id: dict, max_length: int<span style="color:#f92672">=</span><span style="color:#ae81ff">512</span>):
        self<span style="color:#f92672">.</span>tokenizer <span style="color:#f92672">=</span> tokenizer
        self<span style="color:#f92672">.</span>label2id <span style="color:#f92672">=</span> label2id
        self<span style="color:#f92672">.</span>max_length <span style="color:#f92672">=</span> max_length
        self<span style="color:#f92672">.</span>clf_token <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>tokenizer<span style="color:#f92672">.</span>vocab[<span style="color:#e6db74">&#39;[CLS]&#39;</span>]
        self<span style="color:#f92672">.</span>pad_token <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>tokenizer<span style="color:#f92672">.</span>vocab[<span style="color:#e6db74">&#39;[PAD]&#39;</span>]

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">encode</span>(self, input):
    <span style="color:#66d9ef">return</span> list(self<span style="color:#f92672">.</span>tokenizer<span style="color:#f92672">.</span>convert_tokens_to_ids(o) <span style="color:#66d9ef">for</span> o <span style="color:#f92672">in</span> input)

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">token2id</span>(self, item: Tuple[str, str]):
    <span style="color:#e6db74">&#34;Convert text (item[0]) to sequence of IDs and label (item[1]) to integer&#34;</span>
    <span style="color:#66d9ef">assert</span> len(item) <span style="color:#f92672">==</span> <span style="color:#ae81ff">2</span>   <span style="color:#75715e"># Need a row of text AND labels</span>
    label, text <span style="color:#f92672">=</span> item[<span style="color:#ae81ff">0</span>], item[<span style="color:#ae81ff">1</span>]
    <span style="color:#66d9ef">assert</span> isinstance(text, str)   <span style="color:#75715e"># Need position 1 of input to be of type(str)</span>
    inputs <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>tokenizer<span style="color:#f92672">.</span>tokenize(text)

<span style="color:#66d9ef">if</span> len(inputs) <span style="color:#f92672">&gt;=</span> self<span style="color:#f92672">.</span>max_length:
    inputs <span style="color:#f92672">=</span> inputs[:self<span style="color:#f92672">.</span>max_length <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>]
    ids <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>encode(inputs) <span style="color:#f92672">+</span> [self<span style="color:#f92672">.</span>clf_token]
<span style="color:#66d9ef">else</span>:
    pad <span style="color:#f92672">=</span> [self<span style="color:#f92672">.</span>pad_token] <span style="color:#f92672">*</span> (self<span style="color:#f92672">.</span>max_length <span style="color:#f92672">-</span> len(inputs) <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>)
    ids <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>encode(inputs) <span style="color:#f92672">+</span> [self<span style="color:#f92672">.</span>clf_token] <span style="color:#f92672">+</span> pad

<span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>array(ids, dtype<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;int64&#39;</span>), self<span style="color:#f92672">.</span>label2id[label]

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">process_row</span>(self, row):
    <span style="color:#e6db74">&#34;Calls the token2id method of the text processor for passing items to executor&#34;</span>
    <span style="color:#66d9ef">return</span> self<span style="color:#f92672">.</span>token2id((row[<span style="color:#ae81ff">1</span>][LABEL_COL], row[<span style="color:#ae81ff">1</span>][TEXT_COL]))

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">create_dataloader</span>(self,
                      df: pd<span style="color:#f92672">.</span>DataFrame,
                      batch_size: int <span style="color:#f92672">=</span> <span style="color:#ae81ff">32</span>,
                      shuffle: bool <span style="color:#f92672">=</span> False,
                      valid_pct: float <span style="color:#f92672">=</span> None):
    <span style="color:#e6db74">&#34;Process rows in pd.DataFrame using n_cpus and return a DataLoader&#34;</span>

tqdm<span style="color:#f92672">.</span>pandas()
<span style="color:#66d9ef">with</span> ProcessPoolExecutor(max_workers<span style="color:#f92672">=</span>n_cpu) <span style="color:#66d9ef">as</span> executor:
    result <span style="color:#f92672">=</span> list(
        tqdm(executor<span style="color:#f92672">.</span>map(self<span style="color:#f92672">.</span>process_row, df<span style="color:#f92672">.</span>iterrows(), chunksize<span style="color:#f92672">=</span><span style="color:#ae81ff">8192</span>),
             desc<span style="color:#f92672">=</span>f<span style="color:#e6db74">&#34;Processing {len(df)} examples on {n_cpu} cores&#34;</span>,
             total<span style="color:#f92672">=</span>len(df)))

features <span style="color:#f92672">=</span> [r[<span style="color:#ae81ff">0</span>] <span style="color:#66d9ef">for</span> r <span style="color:#f92672">in</span> result]
labels <span style="color:#f92672">=</span> [r[<span style="color:#ae81ff">1</span>] <span style="color:#66d9ef">for</span> r <span style="color:#f92672">in</span> result]

dataset <span style="color:#f92672">=</span> TensorDataset(torch<span style="color:#f92672">.</span>tensor(features, dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>long),
                        torch<span style="color:#f92672">.</span>tensor(labels, dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>long))

data_loader <span style="color:#f92672">=</span> DataLoader(dataset,
                         batch_size<span style="color:#f92672">=</span>batch_size,
                         num_workers<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>,
                         shuffle<span style="color:#f92672">=</span>shuffle,
                         pin_memory<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>cuda<span style="color:#f92672">.</span>is_available())
<span style="color:#66d9ef">return</span> data_loader
</code></pre></div>
            </div>
        </article>

        <hr />

        <div class="post-info">
  				<p>
  					<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line></svg><span class="tag"><a href="https://dragarok.github.io/tags/tokenization">tokenization</a></span><span class="tag"><a href="https://dragarok.github.io/tags/bert">bert</a></span>
  				</p>
  			</div>

        
    </main>

            </div>

            
                <footer class="footer">
    <div class="footer__inner">
        <div class="footer__content">
            <span>&copy; 2020</span>
            
                <span><a href="https://dragarok.github.io/">Alok Regmi</a></span>
            
                
            <span>Theme by <a href="https://github.com/rhazdon">Djordje Atlialp</a></span>
        </div>
    </div>
    
</footer>

            
        </div>

        




<script type="text/javascript" src="../../bundle.min.2d5469329143160ae2456a69c3c76dc2d0a3b212b46afe291a51bd68650ed6f8697e001dab54f1c272c77ce08092a8c55e5bb4314e0ee334aab4b927ec896638.js" integrity="sha512-LVRpMpFDFgriRWppw8dtwtCjshK0av4pGlG9aGUO1vhpfgAdq1TxwnLHfOCAkqjFXlu0MU4O4zSqtLkn7IlmOA=="></script>



    </body>
</html>

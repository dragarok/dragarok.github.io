<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="author" content="[Alok Regmi]">
<meta name="description" content="Efficient Nets: Why all this ? &amp;ndash; Scaling CNN’s only in one direction (eg depth only) will result in rapidly deteriorating gains relative to the computational increase needed.
&amp;ndash; ResNet 1000 isn’t much more accurate than ResNet152 for example, as after 100 -150 layer’s gains rapidly drop off.
&amp;ndash; Scaling depth, width and resolution all benifits quickly saturate so not at all possibility of sota.
We now know the problem so let&amp;rsquo;s do this instead: &amp;ndash; In order to scale up efficiently, all dimensions of depth, width and resolution have to be scaled together, and there is an optimal balance for each dimension relative to the others." />
<meta name="keywords" content="Blog, neuralnetwork, architecture, vision" />
<meta name="robots" content="noodp" />
<meta name="theme-color" content="" />
<link rel="canonical" href="https://dragarok.github.io/ai/efficient_nets/" />


    <title>
        
            Efficient Nets ::  
        
    </title>



<link href="https://cdnjs.cloudflare.com/ajax/libs/flag-icon-css/3.2.1/css/flag-icon.min.css" rel="stylesheet"
    type="text/css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
    
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
    
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>





<link rel="stylesheet" href="../../main.min.47d1ac1539fe1320a4309408fbd7b3a0a50b48482799b1e81ee0115e02cb24e2.css">




    <link rel="apple-touch-icon" sizes="180x180" href="../../apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../../favicon-16x16.png">
    <link rel="manifest" href="../../site.webmanifest">
    <link rel="mask-icon" href="../../safari-pinned-tab.svg" color="#252627">
    <link rel="shortcut icon" href="../../favicon.ico">
    <meta name="msapplication-TileColor" content="#252627">
    <meta name="theme-color" content="#252627">

<meta itemprop="name" content="Efficient Nets">
<meta itemprop="description" content="Efficient Nets: Why all this ? &ndash; Scaling CNN’s only in one direction (eg depth only) will result in rapidly deteriorating gains relative to the computational increase needed.
&ndash; ResNet 1000 isn’t much more accurate than ResNet152 for example, as after 100 -150 layer’s gains rapidly drop off.
&ndash; Scaling depth, width and resolution all benifits quickly saturate so not at all possibility of sota.
We now know the problem so let&rsquo;s do this instead: &ndash; In order to scale up efficiently, all dimensions of depth, width and resolution have to be scaled together, and there is an optimal balance for each dimension relative to the others."><meta itemprop="datePublished" content="2020-03-20T00:00:00+00:00" />
<meta itemprop="dateModified" content="2020-05-02T04:04:27+05:45" />
<meta itemprop="wordCount" content="295"><meta itemprop="image" content="https://dragarok.github.io/"/>
<meta itemprop="keywords" content="neuralnetwork,architecture,vision," /><meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://dragarok.github.io/"/>

<meta name="twitter:title" content="Efficient Nets"/>
<meta name="twitter:description" content="Efficient Nets: Why all this ? &ndash; Scaling CNN’s only in one direction (eg depth only) will result in rapidly deteriorating gains relative to the computational increase needed.
&ndash; ResNet 1000 isn’t much more accurate than ResNet152 for example, as after 100 -150 layer’s gains rapidly drop off.
&ndash; Scaling depth, width and resolution all benifits quickly saturate so not at all possibility of sota.
We now know the problem so let&rsquo;s do this instead: &ndash; In order to scale up efficiently, all dimensions of depth, width and resolution have to be scaled together, and there is an optimal balance for each dimension relative to the others."/>





    <meta property="article:published_time" content="2020-03-20 00:00:00 &#43;0000 UTC" />








    </head>

    <body class="">
        <div class="container">
            <header class="header">
    <span class="header__inner">
        <a href="../../" style="text-decoration: none;">
    <div class="logo">
        
            <span class="logo__mark">~</span>
            <span class="logo__text">K4iv41y4</span>
            <span class="logo__mark">&nbsp;~</span>
            <span class="logo__cursor" style=
                  "
                   
                   ">
            </span>
        
    </div>
</a>


        <span class="header__right">
            
                <nav class="menu">
    <ul class="menu__inner"><li><a href="https://dragarok.github.io/about/">About</a></li><li><a href="https://dragarok.github.io/ai/">AI</a></li><li><a href="https://dragarok.github.io/posts/">Blog</a></li><li><a href="https://dragarok.github.io/books/">Books</a></li><li><a href="https://dragarok.github.io/braindump/">Braindump</a></li>
    </ul>
</nav>

                <span class="menu-trigger">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                        <path d="M0 0h24v24H0z" fill="none"/>
                        <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
                    </svg>
                </span>
            

            <span class="theme-toggle unselectable"><svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg">
  <path d="M22 41C32.4934 41 41 32.4934 41 22C41 11.5066 32.4934 3 22
  3C11.5066 3 3 11.5066 3 22C3 32.4934 11.5066 41 22 41ZM7 22C7
  13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22Z"/>
</svg>
</span>
        </span>
    </span>
</header>


            <div class="content">
                
    <main class="post">

        <div class="post-info">
            
            </p>
        </div>

        <article>
            <h2 class="post-title"><a href="https://dragarok.github.io/ai/efficient_nets/">Efficient Nets</a></h2>

            

            <div class="post-content">
                <h2 id="efficient-nets">Efficient Nets:</h2>
<ol>
<li>
<p>Why all this ?
&ndash;  Scaling CNN’s only in one direction (eg depth only) will result in rapidly
deteriorating gains relative to the computational increase needed.</p>
<p>&ndash; ResNet 1000 isn’t much more accurate than ResNet152 for example,
as after 100 -150 layer’s gains rapidly drop off.</p>
<p>&ndash; Scaling depth, width and resolution all benifits quickly saturate so
not at all  possibility of sota.</p>
</li>
<li>
<p>We now know the problem so let&rsquo;s do this instead:
&ndash; In order to scale up efficiently, all dimensions of depth,
width and resolution have to be scaled together,
and there is an optimal balance for each dimension relative to the others.
VOILA!!!</p>
<p>&ndash;  after an extensive grid search derived the theoretically optimal formula of “compound scaling” using the following co-efficients:</p>
<p>Depth = 1.20</p>
<p>Width = 1.10</p>
<p>Resolution = 1.15</p>
<p>Only google can do this kind of computational  search !! :(</p>
</li>
<li>
<p>By showing the existing heatmaps in different widths, depths and resolution,
they show that their model captures more real image like features than some
nonsense these NNs learn on the way to correct prediction.
At last!! We can at least have our brothers in image recognition who detects
images more naturally looking on the inside.</p>
</li>
<li>
<p>Now not just large GPUs can do it, my phone can load a model and use it properly.
Thanks to reduced number of parameters. Thanks to Gooooogogoogogogogogle&rsquo;s computational
for having this grid search and the paper.</p>
</li>
</ol>
<!--listend-->
<ol>
<li>Not just google, I need to experiment with how much to give to depth, width and
resolution For example, when given 2^N computational resources,
we could increase network depth by α^N, width by β^N,
and image size by γ^N, where α, β, and γ are constant coefficients
determined by a small grid search on the original small model.</li>
</ol>

            </div>
        </article>

        <hr />

        <div class="post-info">
  				<p>
  					<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line></svg><span class="tag"><a href="https://dragarok.github.io/tags/neuralnetwork">neuralnetwork</a></span><span class="tag"><a href="https://dragarok.github.io/tags/architecture">architecture</a></span><span class="tag"><a href="https://dragarok.github.io/tags/vision">vision</a></span>
  				</p>
  			</div>

        
    </main>

            </div>

        </div>

        




<script type="text/javascript" src="../../bundle.min.fbf016a5f89be88f4916a0898302f777692ee6600991c3b6108fc423ed982dc83b470742cc92dd796861136f5ca96988b35e049b5f4cb4b1343686784a58c8ce.js" integrity="sha512-&#43;/AWpfib6I9JFqCJgwL3d2ku5mAJkcO2EI/EI&#43;2YLcg7RwdCzJLdeWhhE29cqWmIs14Em19MtLE0NoZ4SljIzg=="></script>



    </body>
</html>

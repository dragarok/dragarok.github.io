<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="author" content="[Alok Regmi]">
<meta name="description" content="&amp;ndash; tags: Graph Signal Processing
Intro &amp;ndash; The kernel is defined in Fourier space and graph Fourier transforms are notoriously expensive to compute. &amp;ndash; O(N²) operation for a graph with N nodes: the multiplication operation for i/p nodes and eigenvec of graph&amp;rsquo;s laplacian. &amp;ndash; Thus as a solution to the computational complexity introduced by it, Monte Carlo (biased random sampling method) approaches to consistently estimate the integrals, which allowed for batch training, reducing the overall training time." />
<meta name="keywords" content="Blog" />
<meta name="robots" content="noodp" />
<meta name="theme-color" content="" />
<link rel="canonical" href="https://dragarok.github.io/ai/fast_graphconv_nets/" />


    <title>
        
            Fast GraphConv Nets :: Alok&#39;s Blog 
        
    </title>



<link href="https://cdnjs.cloudflare.com/ajax/libs/flag-icon-css/3.2.1/css/flag-icon.min.css" rel="stylesheet"
    type="text/css">



<link rel="stylesheet" href="../../main.min.84ed5579024525d4b50458514d1a43e40dd5272df45c7cd6da85b225af457154.css">




    <link rel="apple-touch-icon" sizes="180x180" href="../../apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../../favicon-16x16.png">
    <link rel="manifest" href="../../site.webmanifest">
    <link rel="mask-icon" href="../../safari-pinned-tab.svg" color="#252627">
    <link rel="shortcut icon" href="../../favicon.ico">
    <meta name="msapplication-TileColor" content="#252627">
    <meta name="theme-color" content="#252627">

<meta itemprop="name" content="Fast GraphConv Nets">
<meta itemprop="description" content="&ndash; tags: Graph Signal Processing
Intro &ndash; The kernel is defined in Fourier space and graph Fourier transforms are notoriously expensive to compute. &ndash; O(N²) operation for a graph with N nodes: the multiplication operation for i/p nodes and eigenvec of graph&rsquo;s laplacian. &ndash; Thus as a solution to the computational complexity introduced by it, Monte Carlo (biased random sampling method) approaches to consistently estimate the integrals, which allowed for batch training, reducing the overall training time.">
<meta itemprop="datePublished" content="2020-03-12T00:00:00&#43;05:45" />
<meta itemprop="dateModified" content="2020-05-02T03:48:37&#43;05:45" />
<meta itemprop="wordCount" content="135">
<meta itemprop="image" content="https://dragarok.github.io/"/>



<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://dragarok.github.io/"/>

<meta name="twitter:title" content="Fast GraphConv Nets"/>
<meta name="twitter:description" content="&ndash; tags: Graph Signal Processing
Intro &ndash; The kernel is defined in Fourier space and graph Fourier transforms are notoriously expensive to compute. &ndash; O(N²) operation for a graph with N nodes: the multiplication operation for i/p nodes and eigenvec of graph&rsquo;s laplacian. &ndash; Thus as a solution to the computational complexity introduced by it, Monte Carlo (biased random sampling method) approaches to consistently estimate the integrals, which allowed for batch training, reducing the overall training time."/>





    <meta property="article:published_time" content="2020-03-12 00:00:00 &#43;0545 &#43;0545" />








    </head>

    <body class="">
        <div class="container">
            <header class="header">
    <span class="header__inner">
        <a href="../../" style="text-decoration: none;">
    <div class="logo">
        
            <span class="logo__mark">></span>
            <span class="logo__text">K4iv41y4</span>
            <span class="logo__cursor" style=
                  "
                   
                   ">
            </span>
        
    </div>
</a>


        <span class="header__right">
            
                <nav class="menu">
    <ul class="menu__inner"><li><a href="https://dragarok.github.io/about/">About</a></li><li><a href="https://dragarok.github.io/ai/">AI</a></li><li><a href="https://dragarok.github.io/posts/">Blog</a></li><li><a href="https://dragarok.github.io/books/">Books</a></li><li><a href="https://dragarok.github.io/braindump/">Braindump</a></li>
    </ul>
</nav>

                <span class="menu-trigger">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                        <path d="M0 0h24v24H0z" fill="none"/>
                        <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
                    </svg>
                </span>
            

            <span class="theme-toggle unselectable"><svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg">
  <path d="M22 41C32.4934 41 41 32.4934 41 22C41 11.5066 32.4934 3 22
  3C11.5066 3 3 11.5066 3 22C3 32.4934 11.5066 41 22 41ZM7 22C7
  13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22Z"/>
</svg>
</span>
        </span>
    </span>
</header>


            <div class="content">
                
    <main class="post">

        <div class="post-info">
            
            </p>
        </div>

        <article>
            <h2 class="post-title"><a href="https://dragarok.github.io/ai/fast_graphconv_nets/">Fast GraphConv Nets</a></h2>

            

            <div class="post-content">
                <p>&ndash; tags: <a href="../../ai/graph_signal_processing/">Graph Signal Processing</a></p>
<h2 id="intro">Intro</h2>
<p>&ndash; The kernel is defined in Fourier space and graph Fourier transforms are notoriously expensive to compute.
&ndash;  O(N²) operation for a graph with N nodes: the multiplication operation for i/p nodes and eigenvec of graph&rsquo;s laplacian.
&ndash; Thus as a solution to the computational complexity introduced by it, Monte Carlo (biased random sampling method) approaches to consistently estimate the integrals,
which allowed for batch training, reducing the overall training time.
&ndash; We hypothesize that the nonlinearity between GCN layers is not critical — but that the majority of the benefit arises from the local averaging. &ndash;IBM paper on Fast GCN
&ndash; The project removed the nonlinear transition functions between each convolutional layer.
The final softmax activation allowed for probabilistic outputs that can be optimized with stochastic gradient descent.</p>

            </div>
        </article>

        <hr />

        <div class="post-info">
  			</div>

        
    </main>

            </div>

            
                <footer class="footer">
    <div class="footer__inner">
        <div class="footer__content">
            <span>&copy; 2020</span>
            
                <span><a href="https://dragarok.github.io/">Alok Regmi</a></span>
            
                
            <span>Theme by <a href="https://github.com/rhazdon">Djordje Atlialp</a></span>
        </div>
    </div>
    
</footer>

            
        </div>

        




<script type="text/javascript" src="../../bundle.min.2d5469329143160ae2456a69c3c76dc2d0a3b212b46afe291a51bd68650ed6f8697e001dab54f1c272c77ce08092a8c55e5bb4314e0ee334aab4b927ec896638.js" integrity="sha512-LVRpMpFDFgriRWppw8dtwtCjshK0av4pGlG9aGUO1vhpfgAdq1TxwnLHfOCAkqjFXlu0MU4O4zSqtLkn7IlmOA=="></script>



    </body>
</html>

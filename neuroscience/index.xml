<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Neurosciences on </title>
    <link>https://dragarok.github.io/neuroscience/</link>
    <description>Recent content in Neurosciences on </description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Mon, 31 Aug 2020 15:28:41 +0545</lastBuildDate>
    <atom:link href="https://dragarok.github.io/neuroscience/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>FMRI Hyperalignment</title>
      <link>https://dragarok.github.io/neuroscience/fmri_hyperalignment/</link>
      <pubDate>Sat, 29 Aug 2020 00:00:00 +0545</pubDate>
      <guid>https://dragarok.github.io/neuroscience/fmri_hyperalignment/</guid>
      <description>&lt;ul&gt;&#xA;&lt;li&gt;There is a trajectory in VTC compared to a person&amp;rsquo;s visual experience when&#xA;they see different objects around in one trajectory.&lt;/li&gt;&#xA;&lt;li&gt;But relating trajectory in one region of the brain to another in voxel space&#xA;is not easy since it can be very different and non-linearly following as well.&lt;/li&gt;&#xA;&lt;li&gt;But the voxel trajectory for different persons should be same. Sounds&#xA;interesting but comes with a problem. How to know which voxels are same for&#xA;different persons? We do it by estimating that the voxels come from same&#xA;region by comparison to anatomical images.  Now we can rotate and reflect the&#xA;voxel space image to align each other.   &amp;ndash; Haxby 2011&lt;/li&gt;&#xA;&lt;li&gt;You can train for classifying in one person and transform to shared feature&#xA;space, then you can test it on different person based on the shared space of&#xA;representation after mapping with one set of data first.&lt;/li&gt;&#xA;&lt;li&gt;Whole Brain Analysis is generally advantageous with this method.&lt;/li&gt;&#xA;&lt;li&gt;In &lt;strong&gt;Searchlight analysis&lt;/strong&gt;, doing this first is a great way to go.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;backlinks&#34;&gt;Backlinks&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;../neuroscience/fmri_bootcamp/&#34;&gt;FMRI bootcamp&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>FMRI Comparisons and Problems</title>
      <link>https://dragarok.github.io/neuroscience/fmri_comparisons/</link>
      <pubDate>Fri, 28 Aug 2020 00:00:00 +0545</pubDate>
      <guid>https://dragarok.github.io/neuroscience/fmri_comparisons/</guid>
      <description>&lt;ul&gt;&#xA;&lt;li&gt;If only the probability that &lt;strong&gt;Null Hypothesis&lt;/strong&gt; is less than 1/20, the experiment&#xA;is of scientific interest.&lt;/li&gt;&#xA;&lt;li&gt;If we treat each voxel as independent test of the hypothesis, there will be&#xA;sure chances to see some example that follows null hypothesis.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;If there are 20 independent experiments, then the probability of finding a&#xA;false positive is 0.64&lt;/li&gt;&#xA;&lt;li&gt;For 200, it&amp;rsquo;s 0.99.&lt;/li&gt;&#xA;&lt;li&gt;Now if we are taking 20k voxels each treated as independent experiments, we&#xA;are surely to find some voxels that will pass as null hypothesis.&lt;/li&gt;&#xA;&lt;li&gt;All these values are based on the fact that probability that sample is not a&#xA;false positive is 0.05 or 1 out of 20.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;This occurs when we want to find region or voxel that activates to certain&#xA;stimuli : if we don&amp;rsquo;t take all the voxels though, this effect of false&#xA;positive will be pretty low but doing a full brain analysis, this effect might&#xA;be pretty huge.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;family-wise-error-fwe&#34;&gt;Family wise Error [FWE]&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Dead Fish Experiment&lt;/strong&gt;  : Showed social vs non-social movies. Then comparing&#xA;between voxels, they found a voxel that could be used to distinguish between&#xA;the social and non-social movies. That was to show the problem with the test.&lt;/li&gt;&#xA;&lt;li&gt;The independent tests of a same hypothesis form a family.&lt;/li&gt;&#xA;&lt;li&gt;On doing experiments, we have to know which experiments are interchangeable so&#xA;that we know  if they belong to a family or not.&lt;/li&gt;&#xA;&lt;li&gt;If you have different experiments running with different hypothesis, they&#xA;don&amp;rsquo;t affect each other as we discussed in the previous paragraph.&lt;/li&gt;&#xA;&lt;li&gt;Compound relationships can be used to relate variables since mostly the&#xA;variables are not independent to each other.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;solving-problem-of-independent-tests&#34;&gt;Solving Problem of independent tests&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Assume each voxel as an independent test&#xA;&lt;ol&gt;&#xA;&lt;li&gt;As spatial resolution increased , the test got worse.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Parametric&#xA;&lt;ol&gt;&#xA;&lt;li&gt;RFT [Random Field Theory]&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Voxelwise&lt;/li&gt;&#xA;&lt;li&gt;Clusterwise : If we have only single voxel that activates to the&#xA;signal, it is pretty likely that it&amp;rsquo;s noise. So, we look at&#xA;neighbouring voxels to see a cluster of activation in the brain. The&#xA;parameters are CDT (Cluster Defining Threshold), Number of contiguous&#xA;voxels passing that threshold. But it is &lt;strong&gt;WRONG&lt;/strong&gt;. The smoothness of BLOD&#xA;signal appearing in the brain was wrong that was assumed in this&#xA;experiment.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Non-parametric test&#xA;&lt;ol&gt;&#xA;&lt;li&gt;For contrast values images, multiply half of images [entire images] with 1&#xA;or -1; then each contrast-value distribution for each voxel has zero mean&#xA;since half of the values are flipped to the other side of distribution.&#xA;This is done for each image from each subject so that the corresponding&#xA;contrast image is never changed. The relationship across subjects is&#xA;changed but not the spatial information of the contrast-image map. Now, we&#xA;get the t-value. Note the max t-value. Now, repeat for like 1000 times,&#xA;and you get a histogram of t-values. Now, we get empirical threshold for&#xA;choosing an active voxel. Choosing this threshold, it automatically makes&#xA;it so that you get a false positive 1/20 time. This is only good for&#xA;second level analysis.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;backlinks&#34;&gt;Backlinks&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;../neuroscience/fmri_bootcamp/&#34;&gt;FMRI bootcamp&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Representational Similarity Analysis</title>
      <link>https://dragarok.github.io/neuroscience/representational_similarity_analysis/</link>
      <pubDate>Fri, 28 Aug 2020 00:00:00 +0545</pubDate>
      <guid>https://dragarok.github.io/neuroscience/representational_similarity_analysis/</guid>
      <description>&lt;ul&gt;&#xA;&lt;li&gt;Question with asking how different or similar are three or more conditions to&#xA;each other?&lt;/li&gt;&#xA;&lt;li&gt;Then we have a similarity matrix. For each new example, how similar are the&#xA;new examples  to the old examples of all classes can be asked.&lt;/li&gt;&#xA;&lt;li&gt;We can measure distance to the clouds of other classes to understand the&#xA;similarity that we observe. We can have information in non-diagonal cells of&#xA;similarity matrix to understand more interesting information about relation&#xA;between these classes.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Classification and Generalization&lt;/strong&gt; in general can be encompassed by RSA.&lt;/li&gt;&#xA;&lt;li&gt;We can have theoretical R.Similarity Matrices and observe region in RDMs&#xA;from experiments to see output similarity to original theoretical idea.&lt;/li&gt;&#xA;&lt;li&gt;Comparing monkey IT region to Human FMRI data. &amp;ndash; Research from &lt;strong&gt;Kriegeskorte&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;Many regions can separate images as classification but we can look at&#xA;off-diagonal cells and understand what property is helping make that&#xA;classification in that region.&lt;/li&gt;&#xA;&lt;li&gt;You have a RSM. To know which model does this data fit to [Theoretical Bases],&#xA;we are faced with a model selection problem.&lt;/li&gt;&#xA;&lt;li&gt;The critical power of RSA is you can have one good collected data and now you&#xA;can build more intelligent models later on to see if they explain the data&#xA;more than your previous models.&lt;/li&gt;&#xA;&lt;li&gt;Behavioral analysis theory, Binary Matrices data, Continuous data, Other&#xA;modalities of neuro-imaging can be used as different models to compete with.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Noise Ceiling:&lt;/strong&gt; Using the same conditions and collecting data again and then&#xA;making a matrix of how good your data quality is.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;backlinks&#34;&gt;Backlinks&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;../neuroscience/fmri_bootcamp/&#34;&gt;FMRI bootcamp&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>FMRI bootcamp</title>
      <link>https://dragarok.github.io/neuroscience/fmri_bootcamp/</link>
      <pubDate>Thu, 13 Aug 2020 00:00:00 +0545</pubDate>
      <guid>https://dragarok.github.io/neuroscience/fmri_bootcamp/</guid>
      <description>&lt;h2 id=&#34;different-views-of-the-brain&#34;&gt;Different views of the brain&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Coronal view: View after cutting the face off.&lt;/li&gt;&#xA;&lt;li&gt;Sagittal medial view: Cutting brain from the sides into the middle.&lt;/li&gt;&#xA;&lt;li&gt;Lateral Sagittal view: Take the skull off.&lt;/li&gt;&#xA;&lt;li&gt;Axial view: Look from the top after cutting off a piece.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../ox-hugo/b57bac4e4c9e0708d7855f9752d6074f8b96ab43.svg&#34; alt=&#34;&#34;&gt;&#xA;&lt;img src=&#34;../ox-hugo/1d91c9ba6831f8332f47a09ab2c5f1418141f44a.svg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Sulca: Bottom of cortical folds&lt;/li&gt;&#xA;&lt;li&gt;Gyrus: Top of cortical folds&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;different-imaging-techniques&#34;&gt;Different Imaging Techniques&lt;/h2&gt;&#xA;&lt;h3 id=&#34;anatomical-imaging&#34;&gt;Anatomical Imaging&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Axial slices are 2D representations.&lt;/li&gt;&#xA;&lt;li&gt;Making multiple axial slices &amp;ndash;&amp;gt; 3D representation of the brain&lt;/li&gt;&#xA;&lt;li&gt;Slices can be separated by some space.&lt;/li&gt;&#xA;&lt;li&gt;Voxel: Spatial Resolution of 3D fMRI representation&lt;/li&gt;&#xA;&lt;li&gt;In plane resolution: Pixel of 2D slice&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Going very high resolution has a downside that the blood flow in the brain&#xA;decreases SNR in our images.&lt;/li&gt;&#xA;&lt;li&gt;Dead brains can be imaged with very high resolution.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Spatial Resolution depends on pixel and separation.&lt;/li&gt;&#xA;&lt;li&gt;Example: 1 mm isotropic , 1*1*1 mm, 176 slices, 5 min : Example of how fMRI&#xA;are defined.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;functional-imaging&#34;&gt;Functional Imaging&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Add temporal resolution to anatomical data. The 3D representation taken in&#xA;different time steps. The time between two images is known as repetition time.&#xA;Generally it&amp;rsquo;s 2 seconds.&lt;/li&gt;&#xA;&lt;li&gt;2 seconds vs 5 minutes: Sacrifice spatial resolution; Generally it&amp;rsquo;s 3*3*3 and&#xA;30 slices.&lt;/li&gt;&#xA;&lt;li&gt;27 anatomical voxels compared to 1 anatomical voxel.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;fmri-time-course&#34;&gt;fMRI Time-course&lt;/h2&gt;&#xA;&lt;h3 id=&#34;hemodynamic-response-function--hrf&#34;&gt;Hemodynamic Response function(HRF)&lt;/h3&gt;&#xA;&lt;figure&gt;&lt;img src=&#34;../ox-hugo/05215436aceef7c091f443ffa5ca06e1e1791055.svg&#34;&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The brain has a high oxygen level in the region after activity. There is a&#xA;undershoot after some time after peak.&lt;/li&gt;&#xA;&lt;li&gt;This is the general HRF used to process fMRI data.&lt;/li&gt;&#xA;&lt;li&gt;HRF looked in baby mice was found to be very slow. Mostly for adults and&#xA;general experiments, the standard HRF is used. α is the time to peak&#xA;which is also called Human Anatomical Lag and β is the peak level. α&#xA;is fixed generally and we solve for β.&lt;/li&gt;&#xA;&lt;li&gt;Variability in α is smaller than β. So, even if we have different&#xA;values of α across different brain regions, we neglect it for general experiments.&lt;/li&gt;&#xA;&lt;li&gt;2 seconds time in Functional fMRI is only useful for the HRF just drawn above.&#xA;So, we need to have it small to resolve the peak of HRF.&lt;/li&gt;&#xA;&lt;li&gt;Big blood vessels at smaller scale can turn into noise around the given voxel.&lt;/li&gt;&#xA;&lt;li&gt;Astrocyte in early visual cortex have 1:1 relation with neurons and can be&#xA;used to get same spatial resolution as the neural activity.&lt;/li&gt;&#xA;&lt;li&gt;The shape of HRF and α is something we take as prior knowledge.&lt;/li&gt;&#xA;&lt;li&gt;Negative β is when given the input signal, the blood oxygen level&#xA;decreases relative to normal case.&lt;/li&gt;&#xA;&lt;li&gt;BLOD signal [ Actual signal ] Unit:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;%SC[Signal Change]: Relative to normal, how different is&#xA;BLOD signal in the experiment.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;general-linear-model--glms&#34;&gt;General Linear Model (GLMs)&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Boxcar regressor : Box shaped signal multiplied by HRF signal.&lt;/li&gt;&#xA;&lt;li&gt;Single GLM with multiple regressors.&lt;/li&gt;&#xA;&lt;li&gt;β values per voxel is taken. So, it&amp;rsquo;s a single 3D image of brain with&#xA;different beta. If you have multiple inputs, there will be multiple β&#xA;values. Or you can have β count = no of runs * no of conditions&lt;/li&gt;&#xA;&lt;li&gt;If you just have β image and don&amp;rsquo;t know how many runs did β came from one&#xA;signal&amp;rsquo;s full time snapshot, then it&amp;rsquo;s ruined data. You need information about&#xA;how the data&amp;rsquo;s obtained as well.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;noise&#34;&gt;Noise:&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;e.g Sneezing where the whole brain breaks and has spike in&#xA;response at that time. People can move their head and these noise make the&#xA;signal unusual or crazy.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Solution:&lt;/strong&gt; To handle this, put an impulse regressor with single&#xA;time-point with same height as the data&amp;rsquo;s amplitude. So, this regressor&#xA;explains whole information and no other regressors don&amp;rsquo;t take into account of&#xA;it since the first one explains it by default.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;steps-in-data-analysis&#34;&gt;Steps in data analysis:&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Raw data: Scanner in DICOOM format.&lt;/li&gt;&#xA;&lt;li&gt;Preprocessing: Motion correction of head, smoothing etc.&lt;/li&gt;&#xA;&lt;li&gt;Modeling: Comparing the data with your prior and your input. The output will&#xA;be β values.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;univariate-analysis&#34;&gt;Univariate analysis&lt;/h2&gt;&#xA;&lt;h3 id=&#34;answer-how-much-is-neural-activity&#34;&gt;Answer &lt;strong&gt;How much&lt;/strong&gt; is neural activity?&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Need to first answer &lt;strong&gt;Where&lt;/strong&gt; question first.&lt;/li&gt;&#xA;&lt;li&gt;Average/Any other metric  of all voxels in the region of interest.  The&#xA;difference of betas between different ROIs is known as &lt;strong&gt;contrast value&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Even though we can&amp;rsquo;t ask &lt;strong&gt;contrast value&lt;/strong&gt;&amp;rsquo;s quantity means but we can see if&#xA;there is a difference in contrast value across different persons.&lt;/li&gt;&#xA;&lt;li&gt;So, this can tell only the &lt;strong&gt;consistency&lt;/strong&gt; of the data using &lt;strong&gt;t-test.&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;answer-where-is-the-neural-activity&#34;&gt;Answer &lt;strong&gt;Where&lt;/strong&gt; is the neural activity?&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;You don&amp;rsquo;t know where you should find the activity.&lt;/li&gt;&#xA;&lt;li&gt;Now for every voxel, &lt;strong&gt;contrast value&lt;/strong&gt; is calculated obtaining a 3D map of brain&#xA;of contrast values.&lt;/li&gt;&#xA;&lt;li&gt;Know the variance of each voxel data from initial beta calculation analysis.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;t-map&lt;/strong&gt; has value at every voxel which is size of &lt;strong&gt;contrast value&lt;/strong&gt; compared to&#xA;the &lt;strong&gt;unexplained variance&lt;/strong&gt; used in calculating initial beta.&lt;/li&gt;&#xA;&lt;li&gt;Now find &lt;strong&gt;big values&lt;/strong&gt; in t-map using &lt;strong&gt;thresholding&lt;/strong&gt;. Generally threshold is&#xA;&amp;lt;0.001. Now, we generally get contiguous voxels as our region. Now, we can use&#xA;this to answer &lt;strong&gt;How much&lt;/strong&gt; question now.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;whole-brain-group-analysis&#34;&gt;Whole Brain Group Analysis&lt;/h3&gt;&#xA;&lt;pre&gt;&lt;code&gt;ID: 827294d7-0097-4aac-a0fc-9b29c6b836d7&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Align brains&#xA;&lt;ol&gt;&#xA;&lt;li&gt;How do you know which voxels are the same in different person?&lt;/li&gt;&#xA;&lt;li&gt;MNI-152 brain. Average &lt;strong&gt;anatomical template&lt;/strong&gt; of brain.&lt;/li&gt;&#xA;&lt;li&gt;Most normalizing images are the functional ones since they are the ones&#xA;that need aligning. So, we &lt;strong&gt;register&lt;/strong&gt; functional mapping to it&amp;rsquo;s analytical&#xA;image and then map it to anatomical template. The first mapping is pretty&#xA;easier compared to the second. These steps are known as &lt;strong&gt;Registration&lt;/strong&gt; and&#xA;&lt;strong&gt;Normalization&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Figure out best fit between the images using affine transformations and&#xA;calculate which point in anatomical brain is similar in the template.&#xA;This is not perfect. For higher regions, the alignment is very poor. Most&#xA;easier to map is V1 and it&amp;rsquo;s also only 40% accurate.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;../neuroscience/fmri_hyperalignment/&#34;&gt;FMRI Hyperalignment&lt;/a&gt; and Functional ROI are other steps that can be added to&#xA;solve the problem with the mapping talked above.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Statistics over people&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Contrast value&lt;/strong&gt; across different person and for specific region, we can&#xA;average &lt;strong&gt;contrast value&lt;/strong&gt; for all persons. Now, for every &lt;strong&gt;contrast map&lt;/strong&gt; across&#xA;persons, &lt;strong&gt;t-map&lt;/strong&gt; by using &lt;strong&gt;variability&lt;/strong&gt; across persons. Then, &lt;strong&gt;threshold&lt;/strong&gt; t-map.&#xA;This statistics over people is known as &lt;strong&gt;Second level Analysis/Random&lt;/strong&gt;&#xA;&lt;strong&gt;Effects Analysis&lt;/strong&gt;. For this analysis, the number of people will define the&#xA;robustness of experiment.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;multivariate-analysis&#34;&gt;Multivariate analysis&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Comparing to the univariate analysis, where we draw different betas across&#xA;voxels distributed in space for different conditions, we know which voxels&#xA;activate to which signal. This was the previous way of analysing our signal.&lt;/li&gt;&#xA;&lt;li&gt;Now, we can represent all voxels as dimension of multidimensional space. If we&#xA;have 12 voxels, it&amp;rsquo;s 12 dimensions. But, we can&amp;rsquo;t observe spatial relation&#xA;between voxels though. We cannot do such analysis with all voxels though.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Which voxels to choose?&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Advantages&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Classification&lt;/li&gt;&#xA;&lt;li&gt;Similarity Analysis using Distance&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;relationship&#34;&gt;Relationship&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Brain region in superior temporal gyrus. &amp;ldquo;TO RUN&amp;rdquo; vs &amp;ldquo;THE ROCK&amp;rdquo;, the words&#xA;have different activity in this region. What is this about? &lt;strong&gt;Verbs vs Nouns&lt;/strong&gt; or&#xA;&lt;strong&gt;Objects in motion vs Stationary Objects&lt;/strong&gt;. This is about testing the question.&lt;/li&gt;&#xA;&lt;li&gt;Experimented with more pair of words drawn from four classes:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Verbs with motion : &amp;ldquo;To run&amp;rdquo;&lt;/li&gt;&#xA;&lt;li&gt;Verbs without motion: &amp;ldquo;To think&amp;rdquo;&lt;/li&gt;&#xA;&lt;li&gt;Nouns with motion: &amp;ldquo;The Tiger&amp;rdquo;&lt;/li&gt;&#xA;&lt;li&gt;Nouns without motion: &amp;ldquo;The Rock&amp;rdquo;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Experimental data:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Prior Analysis&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Time series analysis&lt;/li&gt;&#xA;&lt;li&gt;1 regressor per condition per run&lt;/li&gt;&#xA;&lt;li&gt;8 runs in the experiment&lt;/li&gt;&#xA;&lt;li&gt;4 different conditions&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Total of 32 betas for each voxel found&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Univariate analysis:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Contrast Image&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Running vs Rock in some person which is above the threshold. This is the&#xA;region of interest.&lt;/li&gt;&#xA;&lt;li&gt;We do it for different persons. Now, we say &amp;ldquo;STG&amp;rdquo; is actually where the&#xA;differences occur.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Now , univariate question &amp;ldquo;How much&amp;rdquo; ?&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Averaging over runs. Now, we can have &amp;ldquo;RUN&amp;rdquo; vs &amp;ldquo;ROCK&amp;rdquo; difference of betas.&#xA;We can do it similarly for all sets of differences between conditions:&#xA;&amp;ldquo;nouns vs verbs&amp;rdquo; or &amp;ldquo;motion vs stationary&amp;rdquo;. The differences should be&#xA;larger on the criteria that we intend to find.&lt;/li&gt;&#xA;&lt;li&gt;Now, though you find a distinction, there might be different set of&#xA;differences between the nouns you are taking as well. e.g. &amp;ldquo;The Tiger&amp;rdquo; and&#xA;&amp;ldquo;The Rock&amp;rdquo; might be interpreted into different classes as well. So, this&#xA;goes on. Philosophical debate on &amp;ldquo;non-zero&amp;rdquo; responses in all conditions.&#xA;What does it mean?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Multivariate analysis:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Now, In ROI of around 80 voxels, 8 beta values per run in each condition.&lt;/li&gt;&#xA;&lt;li&gt;In each subject, this can be plotted separately. &amp;ldquo;Leave one out&amp;rdquo; beta&#xA;classification with two boundaries: &amp;ldquo;ROCK and TIGER&amp;rdquo; vs &amp;ldquo;RUNNING&amp;rdquo; and&#xA;&amp;ldquo;THINKING&amp;rdquo;.  Now, can you classify between nouns and verbs inside the&#xA;multivariate analysis. You plot seven betas thus and make boundary. Finally&#xA;you average all those results.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Think about it&lt;/strong&gt; : If we see difference in univariate analysis, there will&#xA;surely be difference in multivariate analysis as well. But, even if there is&#xA;no difference in univariate analysis , there might be difference that could&#xA;be observed in multivariate analysis.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;About the example: We know &amp;ldquo;NOUNS&amp;rdquo; and &amp;ldquo;VERBS&amp;rdquo; were distinctly separated&#xA;in univariate analysis. So, we can separate that boundary clearly in&#xA;multivariate as well. But, can we separate &amp;ldquo;MOTION NOUNS&amp;rdquo; vs &amp;ldquo;STATIONARY&#xA;NOUNS&amp;rdquo; and similarly for verbs is a question that can be answered by&#xA;multivariate analysis only.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Relative information is one that is available in multivariate analysis only.&lt;/li&gt;&#xA;&lt;li&gt;Classification accuracy in verbs and nouns can now be found. This can show&#xA;now that the &amp;ldquo;STG&amp;rdquo; region also has more information to classify between the&#xA;nouns or the verbs if the difference in accuracy is relatively high.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;finding-useful-region&#34;&gt;Finding useful region&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;ROI Identification&lt;/strong&gt; in multivariate analysis. &lt;strong&gt;Where question&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;Commonly known as &lt;strong&gt;Feature Selection&lt;/strong&gt; in ML where the voxels are the features.&lt;/li&gt;&#xA;&lt;li&gt;Choosing Features:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Anatomy  : e.g Amygdala&lt;/li&gt;&#xA;&lt;li&gt;Functional area e.g. SFG [Contiguous regions]&lt;/li&gt;&#xA;&lt;li&gt;Functional PCI-n : Number of voxels in any direction.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why choose voxels?&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Relevant unit of analysis&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Local region: Region with certain characteristic that carries out a&#xA;functional work or encode certain feature space.&lt;/li&gt;&#xA;&lt;li&gt;Functionally defined network: Even if regions are not contiguous, they&#xA;might have functional correlation. e.g. Regions in opposite hemispheres.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Statistical Reasons&#xA;&lt;ul&gt;&#xA;&lt;li&gt;By adding noise i.e. not useful voxels to the total space, we will have low&#xA;SNR: so lower quality of analysis. Thus, we choose only a number of voxels&#xA;for our analysis.&lt;/li&gt;&#xA;&lt;li&gt;Noise also can create significant differences in signal. So, if we know&#xA;relevant voxels, we can ignore voxels that do not help in our analysis. It&#xA;prevents over-fitting in general.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;classification&#34;&gt;Classification&lt;/h2&gt;&#xA;&lt;pre&gt;&lt;code&gt;ID: acb8de53-9d7b-4375-add1-d7a5dd14ba8e&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Example:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Show female sad faces and happy faces. Now, classify them each run, each&#xA;individual and finally average them. This is the first step.&lt;/li&gt;&#xA;&lt;li&gt;We want to know if the emotions in real are making the difference in signal,&#xA;if you show male sad faces and happy faces; if the original boundary&#xA;generalizes to male faces as well, you know that emotions is encoded by that&#xA;region.&lt;/li&gt;&#xA;&lt;li&gt;For number of runs required per person, there is not a fixed number but it&amp;rsquo;s&#xA;generally good to have more runs.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;In binary classification &lt;strong&gt;NEVER&lt;/strong&gt; have unequal number of images in each run.&#xA;Don&amp;rsquo;t let bias get into it.&lt;/li&gt;&#xA;&lt;li&gt;In data, we need to take care of the additional information present in the&#xA;data as well.&lt;/li&gt;&#xA;&lt;li&gt;The overall output was that there was proof for certain region which&#xA;classified general images but could not generalize to cartoon images. And&#xA;there was proof for different region that could generalize to both regions.&#xA;So, one implies only facial information present whereas the other implies more&#xA;to all regions.&lt;/li&gt;&#xA;&lt;li&gt;Generally, you look for main information by comparing different brain regions.&#xA;If you see a likely result from that classification, then there is a&#xA;hierarchical number of analyses that can be done on top of that result.&lt;/li&gt;&#xA;&lt;li&gt;Do positive control such as : Rotation of images and so on. You can do&#xA;negative control as well.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Near Generalization :&lt;/strong&gt; Generalizing to man faces in this case.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Far Generalization&lt;/strong&gt;: Generalizing to cartoon faces as well.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;a href=&#34;../neuroscience/representational_similarity_analysis/&#34;&gt;Representational Similarity Analysis&lt;/a&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
